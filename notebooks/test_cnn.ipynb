{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\pytorch-cpu\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '../utils'))\n",
    "import numpy as np\n",
    "import argparse\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark=True\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"Cnn6\" #Transfer_\n",
    "MODEL_PATH = \"pretrained_models/Cnn6_mAP=0.343.pth\"\n",
    "LABELS_PATH = \"filtered_birds_df.csv\"\n",
    "DATA_PATH = \"audiodata/wav\"\n",
    "\n",
    "NB_SPECIES = 527\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iD</th>\n",
       "      <th>quality</th>\n",
       "      <th>length</th>\n",
       "      <th>country</th>\n",
       "      <th>url</th>\n",
       "      <th>birdName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>548389</td>\n",
       "      <td>A</td>\n",
       "      <td>59</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>www.xeno-canto.org/548389/download</td>\n",
       "      <td>Sturnus vulgaris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546936</td>\n",
       "      <td>A</td>\n",
       "      <td>32</td>\n",
       "      <td>France</td>\n",
       "      <td>www.xeno-canto.org/546936/download</td>\n",
       "      <td>Sturnus vulgaris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>546935</td>\n",
       "      <td>A</td>\n",
       "      <td>65</td>\n",
       "      <td>France</td>\n",
       "      <td>www.xeno-canto.org/546935/download</td>\n",
       "      <td>Sturnus vulgaris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>543800</td>\n",
       "      <td>A</td>\n",
       "      <td>36</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>www.xeno-canto.org/543800/download</td>\n",
       "      <td>Sturnus vulgaris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>542770</td>\n",
       "      <td>A</td>\n",
       "      <td>44</td>\n",
       "      <td>Poland</td>\n",
       "      <td>www.xeno-canto.org/542770/download</td>\n",
       "      <td>Sturnus vulgaris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       iD quality  length         country                                 url  \\\n",
       "0  548389       A      59  United Kingdom  www.xeno-canto.org/548389/download   \n",
       "1  546936       A      32          France  www.xeno-canto.org/546936/download   \n",
       "2  546935       A      65          France  www.xeno-canto.org/546935/download   \n",
       "3  543800       A      36          Sweden  www.xeno-canto.org/543800/download   \n",
       "4  542770       A      44          Poland  www.xeno-canto.org/542770/download   \n",
       "\n",
       "           birdName  \n",
       "0  Sturnus vulgaris  \n",
       "1  Sturnus vulgaris  \n",
       "2  Sturnus vulgaris  \n",
       "3  Sturnus vulgaris  \n",
       "4  Sturnus vulgaris  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn6(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num, freeze_base):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn6, self).__init__()\n",
    "        audioset_classes_num = 527\n",
    "        \n",
    "        self.base = Cnn6(sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "            fmax, audioset_classes_num)\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.fc_transfer = nn.Linear(512, classes_num, bias=True)\n",
    "\n",
    "        if freeze_base:\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint_path):\n",
    "        checkpoint = torch.load(pretrained_checkpoint_path, map_location=torch.device(DEVICE))\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output_dict = self.base(input, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "\n",
    "        clipwise_output =  torch.log_softmax(self.fc_transfer(embedding), dim=-1)\n",
    "        output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 1024\n",
    "hop_size = 320\n",
    "mel_bins = 64\n",
    "fmin = 50\n",
    "fmax = 14000\n",
    "model_type = MODEL_TYPE\n",
    "pretrained_checkpoint_path = MODEL_PATH\n",
    "freeze_base = False\n",
    "\n",
    "sample_rate = 14000\n",
    "classes_num = NB_SPECIES\n",
    "pretrain = True if pretrained_checkpoint_path else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richard\\Anaconda3\\envs\\pytorch-cpu\\lib\\site-packages\\librosa\\filters.py:235: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  warnings.warn('Empty filters detected in mel frequency basis. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnn6(\n",
      "  (spectrogram_extractor): Spectrogram(\n",
      "    (stft): STFT(\n",
      "      (conv_real): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
      "      (conv_imag): Conv1d(1, 513, kernel_size=(1024,), stride=(320,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (logmel_extractor): LogmelFilterBank()\n",
      "  (spec_augmenter): SpecAugmentation(\n",
      "    (time_dropper): DropStripes()\n",
      "    (freq_dropper): DropStripes()\n",
      "  )\n",
      "  (bn0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_block1): ConvBlock5x5(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block2): ConvBlock5x5(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block3): ConvBlock5x5(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_block4): ConvBlock5x5(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc_audioset): Linear(in_features=512, out_features=527, bias=True)\n",
      ")\n",
      "GPU number: 0\n",
      "Load pretrained model successfully!\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "Model = eval(model_type)\n",
    "model = Model(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, \n",
    "    classes_num)#, freeze_base)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Load pretrained model\n",
    "# if pretrain:\n",
    "#     logging.info('Load pretrained model from {}'.format(pretrained_checkpoint_path))\n",
    "#     model.load_from_pretrain(pretrained_checkpoint_path)\n",
    "\n",
    "checkpoint = torch.load(pretrained_checkpoint_path, map_location=torch.device(DEVICE))\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "\n",
    "\n",
    "# Parallel\n",
    "print('GPU number: {}'.format(torch.cuda.device_count()))\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "if 'cuda' in DEVICE:\n",
    "    model.to(DEVICE)\n",
    "\n",
    "print('Load pretrained model successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_data_to_device(x, device):\n",
    "    if 'float' in str(x.dtype):\n",
    "        x = torch.Tensor(x)\n",
    "    elif 'int' in str(x.dtype):\n",
    "        x = torch.LongTensor(x)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "    return x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "offset=5\n",
    "duration=10\n",
    "birdName = \"linaria_cannabina\"\n",
    "filename = \"linaria_cannabina_120708.wav\"\n",
    "audio_path = f\"{DATA_PATH}/{birdName}/{filename}\"\n",
    "\n",
    "(waveform, _) = librosa.core.load(audio_path, sr=sample_rate, mono=True,offset=offset,duration=duration)\n",
    "\n",
    "waveform = waveform[None, :]    # (1, audio_length)\n",
    "waveform = move_data_to_device(waveform, device)\n",
    "batch_output_dict = model(waveform, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipwise_output = batch_output_dict['clipwise_output'].data.cpu().numpy()[0]\n",
    "\n",
    "sorted_indexes = np.argsort(clipwise_output)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137 '/m/04rlf' 'Music']: 0.394\n",
      "[0 '/m/09x0r' 'Speech']: 0.063\n",
      "[300 '/m/07yv9' 'Vehicle']: 0.059\n",
      "[138 '/m/04szw' 'Musical instrument']: 0.038\n",
      "[329 '/m/07jdr' 'Train']: 0.028\n",
      "[239 '/m/02lkt' 'Electronic music']: 0.023\n",
      "[496 '/m/07rcgpl' 'Hum']: 0.019\n",
      "[332 '/m/01g50p' 'Railroad car, train wagon']: 0.019\n",
      "[72 '/m/0jbk' 'Animal']: 0.018\n",
      "[328 '/m/06d_3' 'Rail transport']: 0.018\n"
     ]
    }
   ],
   "source": [
    "#Print audio tagging top probabilities\n",
    "labels = pd.read_csv(\"audioset_tagging_cnn_class_labels_indices.csv\")\n",
    "for k in range(10):\n",
    "    print('{}: {:.3f}'.format(np.array(labels)[sorted_indexes[k]], \n",
    "        clipwise_output[sorted_indexes[k]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, '/t/dd00005', 'Child singing'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(clipwise_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39386606"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(clipwise_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
